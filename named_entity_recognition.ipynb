{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"dslim/bert-base-NER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334a9c9c00814ef6a4cffcd6fee99e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e855509a16c4f46b319b3d427563528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a09caae84443a2b49f29e7fae43626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81be19244fb0473bae50ffb8bdb12973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52c56fad00e4ad786638b49fddf8d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id) #huggingface model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb0a844095141eab0df0b338c5beac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "ner_model = AutoModelForTokenClassification.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp pipeline\n",
    "nlp = pipeline('ner', model=ner_model, tokenizer=tokenizer, aggregation_strategy = 'max', device = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"“We formed our partnership with OpenAI around a shared ambition to responsibly advance cutting-edge AI \\\n",
    "    research and democratize AI as a new technology platform,” said Satya Nadella, Chairman and CEO, Microsoft.\\\n",
    "          “In this next phase of our partnership, developers and organizations across industries will have access\\\n",
    "              to the best AI infrastructure, models, and toolchain with Azure to build and run their applications.”\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORG',\n",
       "  'score': 0.99865675,\n",
       "  'word': 'OpenAI',\n",
       "  'start': 32,\n",
       "  'end': 38},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.9881143,\n",
       "  'word': 'AI',\n",
       "  'start': 100,\n",
       "  'end': 102},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.9725788,\n",
       "  'word': 'AI',\n",
       "  'start': 132,\n",
       "  'end': 134},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.99965036,\n",
       "  'word': 'Satya Nadella',\n",
       "  'start': 171,\n",
       "  'end': 184},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9988427,\n",
       "  'word': 'Microsoft',\n",
       "  'start': 204,\n",
       "  'end': 213},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.9932892,\n",
       "  'word': 'AI',\n",
       "  'start': 353,\n",
       "  'end': 355},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9938997,\n",
       "  'word': 'Azure',\n",
       "  'start': 399,\n",
       "  'end': 404}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Pinecone\n",
    "1. Clean pinecone index\n",
    "2. Init pinecone\n",
    "3. Delete data from index\n",
    "4. Load libraries for NER\n",
    "5. Load libraries for retriever\n",
    "6. Upsert data\n",
    "7. Query data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"key\"\n",
    "env = \"env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone import Pinecone, PodSpec\n",
    "from tqdm.autonotebook import tqdm\n",
    "pc = Pinecone(api_key=api_key)\n",
    "#delete data in old index (delete the actual index in the Pinecone client)\n",
    "idx = pc.Index('medium-data')\n",
    "idx.delete(delete_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp pipeline\n",
    "nlp = pipeline('ner', model=ner_model, tokenizer=tokenizer, aggregation_strategy = 'max', device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9997382,\n",
       "  'word': 'Bill Gates',\n",
       "  'start': 0,\n",
       "  'end': 10},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.99829453,\n",
       "  'word': 'Microsoft',\n",
       "  'start': 29,\n",
       "  'end': 38}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"Bill Gates is the founder of Microsoft\") #test the changed nlp using cpu as engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3880bb03304aa9bbe7554c443b9f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/737 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd7caa37b3949d39119f4420b0a3b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b63d091bcc748568a5ec9fade21ace6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/9.85k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9d07ba685f4809bbe46a845f49efd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/591 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85aebfe74ca34f46b6d9ae0dca5ab957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b022fbece0fd44aa889bf0b7db12deb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data_config.json:   0%|          | 0.00/15.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ecca6757cbd433b9527b7c5e27951fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e134eea2d6fc414c9b75da3d443c6109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45022a30b909469fa48c26fbd5c66567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6525a0747d40778f44b366d9542abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dff13e4919547c89ed677264c14a407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/383 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f635e084d540a5a7b8802a64e4ee05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264380b117bf42efae2ebd77d6b3df0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb6a150141e486e8e1371394074b047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "#https://huggingface.co/flax-sentence-embeddings/all_datasets_v3_mpnet-base\n",
    "#NOTE: Vector size is 768 in dimension\n",
    "retriever = SentenceTransformer(\"flax-sentence-embeddings/all_datasets_v3_mpnet-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.create_index(name='medium-data',dimension=768,metric='cosine',spec=PodSpec(\n",
    "    environment=env,\n",
    "    pod_type= \"p1.x1\",\n",
    "    pods= 1\n",
    "  ))\n",
    "idx = pc.Index('medium-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773bec9c53ce439a82641d51723497cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f038ea46644ba6a429111d070c1db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = load_dataset(\"fabiochiu/medium-articles\", data_files=\"medium_articles.csv\", split=\"train\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = df.dropna().sample(100, random_state=45) #10k can take more than 1h when embedding & upserting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short['text_extended'] = df_short['title'] + '.' + df_short['text'].str[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = df_short['text_extended'].iloc[0:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[item['word'] for item in nlp(batch)] #list of entities for 1 document when batch = iloc[0]\n",
    "len(nlp(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for entity extraction\n",
    "def extract_entities(batch):\n",
    "    entities = []\n",
    "    for doc in batch:\n",
    "        entities.append([item['word'] for item in nlp(doc)])\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retriever.encode(batch[0])) #note 768, same as our dimensions in Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding for batch\n",
    "#emb = retriever.encode(batch).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main script, embedding, creating metadata, upserting to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbystrom\\AppData\\Local\\Temp\\ipykernel_4128\\1559257549.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['named_entity'] = [list(set(entity)) for entity in entities]\n",
      "C:\\Users\\rbystrom\\AppData\\Local\\Temp\\ipykernel_4128\\1559257549.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['named_entity'] = [list(set(entity)) for entity in entities]\n",
      "C:\\Users\\rbystrom\\AppData\\Local\\Temp\\ipykernel_4128\\1559257549.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['named_entity'] = [list(set(entity)) for entity in entities]\n",
      "C:\\Users\\rbystrom\\AppData\\Local\\Temp\\ipykernel_4128\\1559257549.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['named_entity'] = [list(set(entity)) for entity in entities]\n",
      "C:\\Users\\rbystrom\\AppData\\Local\\Temp\\ipykernel_4128\\1559257549.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['named_entity'] = [list(set(entity)) for entity in entities]\n",
      "C:\\Users\\rbystrom\\AppData\\Local\\Temp\\ipykernel_4128\\1559257549.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['named_entity'] = [list(set(entity)) for entity in entities]\n",
      "C:\\Users\\rbystrom\\AppData\\Local\\Temp\\ipykernel_4128\\1559257549.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['named_entity'] = [list(set(entity)) for entity in entities]\n",
      "C:\\Users\\rbystrom\\AppData\\Local\\Temp\\ipykernel_4128\\1559257549.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['named_entity'] = [list(set(entity)) for entity in entities]\n",
      "C:\\Users\\rbystrom\\AppData\\Local\\Temp\\ipykernel_4128\\1559257549.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['named_entity'] = [list(set(entity)) for entity in entities]\n",
      "C:\\Users\\rbystrom\\AppData\\Local\\Temp\\ipykernel_4128\\1559257549.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['named_entity'] = [list(set(entity)) for entity in entities]\n",
      "C:\\Users\\rbystrom\\AppData\\Local\\Temp\\ipykernel_4128\\1559257549.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['named_entity'] = [list(set(entity)) for entity in entities]\n",
      "C:\\Users\\rbystrom\\AppData\\Local\\Temp\\ipykernel_4128\\1559257549.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['named_entity'] = [list(set(entity)) for entity in entities]\n",
      "C:\\Users\\rbystrom\\AppData\\Local\\Temp\\ipykernel_4128\\1559257549.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['named_entity'] = [list(set(entity)) for entity in entities]\n",
      "C:\\Users\\rbystrom\\AppData\\Local\\Temp\\ipykernel_4128\\1559257549.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['named_entity'] = [list(set(entity)) for entity in entities]\n",
      "C:\\Users\\rbystrom\\AppData\\Local\\Temp\\ipykernel_4128\\1559257549.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['named_entity'] = [list(set(entity)) for entity in entities]\n",
      "C:\\Users\\rbystrom\\AppData\\Local\\Temp\\ipykernel_4128\\1559257549.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['named_entity'] = [list(set(entity)) for entity in entities]\n",
      "C:\\Users\\rbystrom\\AppData\\Local\\Temp\\ipykernel_4128\\1559257549.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['named_entity'] = [list(set(entity)) for entity in entities]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "batch_size = 64\n",
    "for i in range(0, len(df_short), batch_size):\n",
    "    #start and end index of each batch\n",
    "    i_end = min(i+batch_size, len(df_short))\n",
    "    print(i, i_end) #keep track of the progress\n",
    "    #get a batch of data\n",
    "    batch = df_short.iloc[i:i_end]\n",
    "    #embedding\n",
    "    emb = retriever.encode(batch['text_extended'].tolist()).tolist()\n",
    "    #NER extraction\n",
    "    entities = extract_entities(batch['text_extended'].tolist())\n",
    "    #[[]] --> [set1, set2, ...]\n",
    "    batch['named_entity'] = [list(set(entity)) for entity in entities] \n",
    "    #removing duplicates, one list per document\n",
    "\n",
    "    #create metadata\n",
    "    batch = batch.drop('text', axis=1)\n",
    "    metadata = batch.to_dict(orient='records')\n",
    "\n",
    "    ids = [f\"{index}\" for index in range(i, i_end)]\n",
    "    vectors_upsert = list(zip(ids, emb, metadata))\n",
    "    _ = idx.upsert(vectors=vectors_upsert)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Wordpress\" #Natural Language\n",
    "qx = retriever.encode(query).tolist() #Query vector (embedded)\n",
    "ne = extract_entities([query])[0] #Named entity as search filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc = idx.query(vector=qx, top_k=5,include_metadata=True,filter={\"named_entity\": {\"$in\" : ne}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.244298488   ['Unsplash', 'Moritz Mentges', 'WordPress', 'Linux Hosts Inc']\n",
      "0.234006554   []\n",
      "0.232506484   []\n",
      "0.226189375   ['Wyze Cam', 'Ring Alarm', 'Noonlight', 'TechHive', 'Wyze Labs', 'Ring', 'Wyze']\n",
      "0.211620227   ['Guarda Wallet', 'Waves Platform', 'Waves', 'Wallet', 'Guarda']\n"
     ]
    }
   ],
   "source": [
    "for result in xc['matches']:\n",
    "    print(result['score'], ' ', result['metadata']['named_entity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better results when the whole dataset is imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
